# -*- coding: utf-8 -*-
"""Quantitative_Qualitative_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rNh4tWJCy-43I87sfB0yndtyBQAb2Tpl

### Data Loading, Cleaning, and Overview
"""

# Data Loading and Preparation

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Set plot style
sns.set_theme(style="whitegrid", font_scale=1.2)
plt.rcParams["figure.dpi"] = 120

# Load data
df = pd.read_excel("Final_Data_With_Conversation.xlsx")

# Quick data overview
display(df.head())
print("Shape:", df.shape)
print("Columns:", df.columns.tolist())

# Check for missing values
missing = df.isnull().sum()
print("Missing values per column:\n", missing[missing > 0])

"""### Descriptive Statistics & Visualization of Key Variables"""

print(df.columns.tolist())

"""
Quick note from Pejman: This section provides summary statistics and visualizations for the main outcome variables:
technology acceptance rate, perceived empathy, user satisfaction, and treatment outcomes.
The histograms show the distribution of each variable across all participants,
helping to identify patterns, skewness, or outliers in the data before moving on to hypothesis testing.
"""

# Clean column names (remove leading/trailing spaces)
df.columns = df.columns.str.strip()

# Key variables for summary
key_vars = [
    "Technology acceptance rate",
    "Level of empathy percieved",
    "User satisfaction",
    "Treatment Outcomes"
]

# Summary statistics
display(df[key_vars].describe())

# Histograms for key variables
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()

for i, var in enumerate(key_vars):
    sns.histplot(df[var], kde=True, ax=axes[i], color=sns.color_palette("deep")[i])
    axes[i].set_title(var)
    axes[i].set_xlabel("")
    axes[i].set_ylabel("Count")

plt.tight_layout()
plt.savefig("descriptive_histograms.png", bbox_inches="tight")
plt.show()

"""### EDA

"""

import pandas as pd
import difflib

df = pd.read_excel('Final_data.xlsx')
print("Actual columns in my file:")
print(df.columns.tolist())

# Intended columns
intended_cols = [
    'Age', 'Sex', 'Time taken', 'Student status', 'Employment status',
    'Treatment Outcomes', 'User satisfaction', 'Level of empathy percieved',
    'Participant Problem', 'Participant Advice Style', 'Participant Told Chat With'
]

# Fuzzy matching to map intended to actual columns
col_map = {}
for col in intended_cols:
    match = difflib.get_close_matches(col, df.columns, n=1, cutoff=0.6)
    if match:
        col_map[col] = match[0]
    else:
        col_map[col] = None

print("\nColumn mapping (intended -> actual):")
for k, v in col_map.items():
    print(f"{k} -> {v}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Load data
df = pd.read_excel('Final_data.xlsx')

# Feature engineering
df['Time taken (min)'] = pd.to_numeric(df['Time taken'], errors='coerce') / 60
df['AI Transparency'] = df['Participant Told Chat With'].replace({'human': 'AI-Unaware', 'AI': 'AI-Aware'})

# Use correct column names
cols = [
    'Age', 'Sex', 'Time taken (min)', 'Student status', 'Employment status',
    'Treatment Outcomes', 'User satisfaction ', 'Level of empathy percieved',
    'Participant Problem', 'Participant Advice Style', 'AI Transparency'
]
df = df[cols]

# Descriptive statistics
desc = df.describe(include='all')
print(desc)

# Distribution plots
plt.figure(figsize=(16, 10))
for i, col in enumerate(['Age', 'Time taken (min)', 'User satisfaction ', 'Level of empathy percieved', 'Treatment Outcomes']):
    plt.subplot(2, 3, i+1)
    sns.histplot(df[col].dropna(), kde=True)
    plt.title(f'Distribution of {col.strip()}')
plt.tight_layout()
plt.show()

# Categorical variable counts
cat_vars = ['Sex', 'Student status', 'Employment status', 'AI Transparency', 'Participant Problem', 'Participant Advice Style']
for col in cat_vars:
    plt.figure(figsize=(6, 4))
    sns.countplot(data=df, x=col, order=df[col].value_counts().index)
    plt.title(f'Count of {col}')
    plt.xticks(rotation=30)
    plt.tight_layout()
    plt.show()

# Boxplots for group comparisons
group_vars = ['Sex', 'Student status', 'Employment status', 'AI Transparency']
target_vars = ['User satisfaction ', 'Level of empathy percieved', 'Treatment Outcomes']
for g in group_vars:
    for t in target_vars:
        plt.figure(figsize=(7, 5))
        sns.boxplot(data=df, x=g, y=t)
        plt.title(f'{t.strip()} by {g}')
        plt.tight_layout()
        plt.show()

# Correlation heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(df[['Age', 'Time taken (min)', 'User satisfaction ', 'Level of empathy percieved', 'Treatment Outcomes']].corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Pairplot for main continuous variables
sns.pairplot(df[['Age', 'Time taken (min)', 'User satisfaction ', 'Level of empathy percieved', 'Treatment Outcomes', 'AI Transparency']], hue='AI Transparency')
plt.show()

# Statistical tests: Example t-test for AI Transparency effect on User satisfaction
ai_aware = df[df['AI Transparency'] == 'AI-Aware']['User satisfaction '].dropna()
ai_unaware = df[df['AI Transparency'] == 'AI-Unaware']['User satisfaction '].dropna()
t_stat, p_val = stats.ttest_ind(ai_aware, ai_unaware, equal_var=False)
print(f"T-test User satisfaction (AI-Aware vs AI-Unaware): t={t_stat:.2f}, p={p_val:.4f}")

# Chi-square test for categorical associations
from scipy.stats import chi2_contingency
for col in ['Sex', 'Student status', 'Employment status']:
    ct = pd.crosstab(df[col], df['AI Transparency'])
    chi2, p, dof, ex = chi2_contingency(ct)
    print(f"Chi-square {col} vs AI Transparency: chi2={chi2:.2f}, p={p:.4f}")

# Save cleaned data for further analysis
df.to_csv('cleaned_final_data.csv', index=False)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_excel('Final_data.xlsx')
df['Time taken (min)'] = pd.to_numeric(df['Time taken'], errors='coerce') / 60
df['AI Transparency'] = df['Participant Told Chat With'].replace({'human': 'AI-Unaware', 'AI': 'AI-Aware'})

# 1. Pairplot for continuous variables, colored by AI Transparency
pairplot_vars = [
    'Age', 'Time taken (min)', 'Level of empathy percieved',
    'User satisfaction ', 'Treatment Outcomes'
]
sns.pairplot(
    df[pairplot_vars + ['AI Transparency']],
    hue='AI Transparency',
    diag_kind='kde',
    plot_kws={'alpha': 0.7, 's': 40}
)
plt.suptitle('Pairplot of Key Variables by AI Transparency', y=1.02)
plt.show()

# 2. Countplots for categorical variables by AI Transparency
cat_vars = ['Participant Advice Style', 'Participant Problem']
for var in cat_vars:
    plt.figure(figsize=(8, 5))
    sns.countplot(
        data=df,
        x=var,
        hue='AI Transparency',
        palette='Set2'
    )
    plt.title(f'{var} by AI Transparency')
    plt.xticks(rotation=30)
    plt.tight_layout()
    plt.show()

# 3. Group-wise descriptive statistics (printed in terminal)
grouped = df.groupby('AI Transparency')[
    ['Age', 'Time taken (min)', 'Level of empathy percieved', 'User satisfaction ', 'Treatment Outcomes']
].describe()
print("\nDescriptive statistics by AI Transparency:\n")
print(grouped)

# Frequency tables for categorical variables
for var in cat_vars:
    print(f"\nFrequency of {var} by AI Transparency:\n")
    print(pd.crosstab(df[var], df['AI Transparency']))

"""### Hypotheses"""

# Quantitative Statistical Analysis
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind, chi2_contingency
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.multicomp import pairwise_tukeyhsd

# Load data
df = pd.read_excel("Final_Data_With_Conversation.xlsx")
df.columns = df.columns.str.strip()

# --- H1: AI Transparency on Empathy, Satisfaction, Treatment Outcomes ---
df['AI Transparency'] = df['Participant Told Chat With'].replace({'human': 'AI-Unaware', 'AI': 'AI-Aware'})
ai_aware = df[df['AI Transparency'] == 'AI-Aware']
ai_unaware = df[df['AI Transparency'] == 'AI-Unaware']

empathy_aware = ai_aware['Level of empathy percieved']
empathy_unaware = ai_unaware['Level of empathy percieved']
satisfaction_aware = ai_aware['User satisfaction']
satisfaction_unaware = ai_unaware['User satisfaction']
treatment_aware = ai_aware['Treatment Outcomes']
treatment_unaware = ai_unaware['Treatment Outcomes']

empathy_ttest = ttest_ind(empathy_aware, empathy_unaware, equal_var=False)
satisfaction_ttest = ttest_ind(satisfaction_aware, satisfaction_unaware, equal_var=False)
treatment_ttest = ttest_ind(treatment_aware, treatment_unaware, equal_var=False)

ttest_results = pd.DataFrame({
    'Measure': ['Empathy', 'User Satisfaction', 'Treatment Outcomes'],
    't-statistic': [empathy_ttest.statistic, satisfaction_ttest.statistic, treatment_ttest.statistic],
    'p-value': [empathy_ttest.pvalue, satisfaction_ttest.pvalue, treatment_ttest.pvalue]
})
print("\nH1 T-test Results:\n", ttest_results)

fig, axes = plt.subplots(1, 3, figsize=(18, 6))
palette = ['#4B9CD3', '#A1D99B']
order = ['AI-Unaware', 'AI-Aware']

sns.boxplot(x='AI Transparency', y='Level of empathy percieved', data=df, ax=axes[0], order=order, palette=palette, showmeans=True,
            meanprops={"marker":"o", "markerfacecolor":"white", "markeredgecolor":"black"})
axes[0].set_title("Empathy")
axes[0].set_xlabel("")
axes[0].set_ylabel("Level of Empathy Perceived")
if empathy_ttest.pvalue < 0.05:
    axes[0].text(0.5, max(empathy_aware.max(), empathy_unaware.max()) + 1, '*', ha='center', va='center', fontsize=24, color='red')

sns.boxplot(x='AI Transparency', y='User satisfaction', data=df, ax=axes[1], order=order, palette=palette, showmeans=True,
            meanprops={"marker":"o", "markerfacecolor":"white", "markeredgecolor":"black"})
axes[1].set_title("User Satisfaction")
axes[1].set_xlabel("")
axes[1].set_ylabel("User Satisfaction")
if satisfaction_ttest.pvalue < 0.05:
    axes[1].text(0.5, max(satisfaction_aware.max(), satisfaction_unaware.max()) + 1, '*', ha='center', va='center', fontsize=24, color='red')

sns.boxplot(x='AI Transparency', y='Treatment Outcomes', data=df, ax=axes[2], order=order, palette=palette, showmeans=True,
            meanprops={"marker":"o", "markerfacecolor":"white", "markeredgecolor":"black"})
axes[2].set_title("Treatment Outcomes")
axes[2].set_xlabel("")
axes[2].set_ylabel("Treatment Outcomes")
if treatment_ttest.pvalue < 0.05:
    axes[2].text(0.5, max(treatment_aware.max(), treatment_unaware.max()) + 1, '*', ha='center', va='center', fontsize=24, color='red')

for ax in axes:
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.grid(axis='y', linestyle='--', alpha=0.7)
    ax.set_xticklabels(order, rotation=15)

fig.suptitle("Effects of AI Transparency on Empathy, Satisfaction, and Treatment Outcomes", fontsize=16, fontweight='bold')
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('H1_professional.png', dpi=300)
plt.show()

# --- H1: ANOVA for Dominant ToC ---
toc_df = df[['Dominant ToC', 'Level of empathy percieved', 'User satisfaction', 'Treatment Outcomes']].rename(
    columns={
        'Dominant ToC': 'Theory_of_Change',
        'Level of empathy percieved': 'Empathy',
        'User satisfaction': 'User_Satisfaction',
        'Treatment Outcomes': 'Treatment_Outcomes'
    }
)

def analyze_anova(outcome):
    model = ols(f'{outcome} ~ C(Theory_of_Change)', data=toc_df).fit()
    anova_results = sm.stats.anova_lm(model, typ=2)
    f_value = anova_results.loc['C(Theory_of_Change)', 'F']
    p_value = anova_results.loc['C(Theory_of_Change)', 'PR(>F)']
    print(f"{outcome}: F = {f_value:.2f}, p = {p_value:.3f}")
    return f_value, p_value

print("\nH1 ANOVA: Dominant ToC Effects")
for outcome in ['Empathy', 'User_Satisfaction', 'Treatment_Outcomes']:
    analyze_anova(outcome)

bar_palette = sns.color_palette("Set2")
for outcome, fname in zip(['Empathy', 'User_Satisfaction', 'Treatment_Outcomes'],
                          ['H1_ANOVA_Empathy.png', 'H1_ANOVA_Satisfaction.png', 'H1_ANOVA_Treatment.png']):
    plt.figure(figsize=(12, 5))
    sns.barplot(x='Theory_of_Change', y=outcome, data=toc_df, palette=bar_palette, ci='sd', capsize=0.1, errwidth=1.5)
    plt.title(f'{outcome} by Dominant Theory of Change', fontsize=14)
    plt.ylabel(outcome)
    plt.xlabel('Dominant ToC')
    plt.tight_layout()
    plt.savefig(fname, dpi=300)
    plt.show()

# --- H2: Emotional ToC by AI Transparency ---
empathy_driven = df[df['Dominant ToC'] == 'Emotional'].copy()
empathy_driven['AI Transparency'] = empathy_driven['Participant Told Chat With'].replace({'human': 'AI-Unaware', 'AI': 'AI-Aware'})
empathy_ai_aware = empathy_driven[empathy_driven['AI Transparency'] == 'AI-Aware']
empathy_ai_unaware = empathy_driven[empathy_driven['AI Transparency'] == 'AI-Unaware']

empathy_aware = empathy_ai_aware['Level of empathy percieved']
empathy_unaware = empathy_ai_unaware['Level of empathy percieved']
satisfaction_aware = empathy_ai_aware['User satisfaction']
satisfaction_unaware = empathy_ai_unaware['User satisfaction']
treatment_aware = empathy_ai_aware['Treatment Outcomes']
treatment_unaware = empathy_ai_unaware['Treatment Outcomes']

empathy_ttest = ttest_ind(empathy_aware, empathy_unaware, equal_var=False)
satisfaction_ttest = ttest_ind(satisfaction_aware, satisfaction_unaware, equal_var=False)
treatment_ttest = ttest_ind(treatment_aware, treatment_unaware, equal_var=False)

ttest_results = pd.DataFrame({
    'Measure': ['Empathy', 'User Satisfaction', 'Treatment Outcomes'],
    't-statistic': [empathy_ttest.statistic, satisfaction_ttest.statistic, treatment_ttest.statistic],
    'p-value': [empathy_ttest.pvalue, satisfaction_ttest.pvalue, treatment_ttest.pvalue]
})
print("\nH2 (Emotional ToC) T-test Results:\n", ttest_results)
ttest_results.to_csv('empathy_driven_ttest_results.csv', index=False)

fig, axes = plt.subplots(1, 3, figsize=(18, 6))
palette = ['#4B9CD3', '#A1D99B']
order = ['AI-Unaware', 'AI-Aware']
for i, (y, title) in enumerate(zip(
    ['Level of empathy percieved', 'User satisfaction', 'Treatment Outcomes'],
    ['Empathy (Emotional ToC)', 'User Satisfaction (Emotional ToC)', 'Treatment Outcomes (Emotional ToC)']
)):
    sns.boxplot(x='AI Transparency', y=y, data=empathy_driven, ax=axes[i], order=order, palette=palette, showmeans=True,
                meanprops={"marker":"o", "markerfacecolor":"white", "markeredgecolor":"black"})
    axes[i].set_title(title)
    axes[i].set_xlabel("")
    axes[i].set_ylabel(y)
fig.suptitle("Outcomes for Participants with an Emotional ToC Based on AI Transparency", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('H2.png', dpi=300)
plt.show()

# --- H3: Rational ToC by AI Transparency ---
practical_driven = df[df['Dominant ToC'] == 'Rational'].copy()
practical_driven['AI Transparency'] = practical_driven['Participant Told Chat With'].replace({'human': 'AI-Unaware', 'AI': 'AI-Aware'})
practical_ai_aware = practical_driven[practical_driven['AI Transparency'] == 'AI-Aware']
practical_ai_unaware = practical_driven[practical_driven['AI Transparency'] == 'AI-Unaware']

empathy_aware = practical_ai_aware['Level of empathy percieved']
empathy_unaware = practical_ai_unaware['Level of empathy percieved']
satisfaction_aware = practical_ai_aware['User satisfaction']
satisfaction_unaware = practical_ai_unaware['User satisfaction']
treatment_aware = practical_ai_aware['Treatment Outcomes']
treatment_unaware = practical_ai_unaware['Treatment Outcomes']

empathy_ttest = ttest_ind(empathy_aware, empathy_unaware, equal_var=False)
satisfaction_ttest = ttest_ind(satisfaction_aware, satisfaction_unaware, equal_var=False)
treatment_ttest = ttest_ind(treatment_aware, treatment_unaware, equal_var=False)

ttest_results = pd.DataFrame({
    'Measure': ['Empathy', 'User Satisfaction', 'Treatment Outcomes'],
    't-statistic': [empathy_ttest.statistic, satisfaction_ttest.statistic, treatment_ttest.statistic],
    'p-value': [empathy_ttest.pvalue, satisfaction_ttest.pvalue, treatment_ttest.pvalue]
})
print("\nH3 (Rational ToC) T-test Results:\n", ttest_results)
ttest_results.to_csv('practical_toc_ttest_results.csv', index=False)

fig, axes = plt.subplots(1, 3, figsize=(18, 6))
for i, (y, title) in enumerate(zip(
    ['Level of empathy percieved', 'User satisfaction', 'Treatment Outcomes'],
    ['Empathy (Rational ToC)', 'User Satisfaction (Rational ToC)', 'Treatment Outcomes (Rational ToC)']
)):
    sns.boxplot(x='AI Transparency', y=y, data=practical_driven, ax=axes[i], order=order, palette=palette, showmeans=True,
                meanprops={"marker":"o", "markerfacecolor":"white", "markeredgecolor":"black"})
    axes[i].set_title(title)
    axes[i].set_xlabel("")
    axes[i].set_ylabel(y)
fig.suptitle("Outcomes for Participants with a Rational ToC Based on AI Transparency", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('H3_rational_toc.png', dpi=300)
plt.show()

# --- H4: Chi-square test: ToC Matches with Advice Style ---
toc_advice_df = df[['Dominant ToC', 'Participant Advice Style']].copy()
expected_advice = {'Emotional': 'empathetic', 'Rational': 'rational'}
toc_advice_df['Advice Match'] = toc_advice_df.apply(
    lambda row: 'Match' if row['Participant Advice Style'] == expected_advice.get(row['Dominant ToC']) else 'Mismatch',
    axis=1
)
contingency_table = pd.crosstab(toc_advice_df['Advice Match'], columns='Count')
print("\nH4: Advice Match Table\n", contingency_table)
chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)
print(f"Chi-square Statistic: {chi2_stat:.3f}, p-value: {p_val:.4f}")

plt.figure(figsize=(6, 4))
palette = {'Match': '#ADD8E6', 'Mismatch': '#A1D99B'}
sns.barplot(x=contingency_table.index, y=contingency_table['Count'], palette=palette)
plt.title("Alignment of Theory of Change with Chosen Advice Style")
plt.xlabel("Advice Style Matches ToC")
plt.ylabel("Number of Participants")
plt.tight_layout()
plt.savefig('H4.png', dpi=300)
plt.show()

# --- H5: Effect of Advice Style on Outcomes ---
empathetic_group = df[df['Participant Advice Style'] == 'empathetic']
rational_group = df[df['Participant Advice Style'] == 'rational']

empathy_empathetic = empathetic_group['Level of empathy percieved']
empathy_rational = rational_group['Level of empathy percieved']
satisfaction_empathetic = empathetic_group['User satisfaction']
satisfaction_rational = rational_group['User satisfaction']
treatment_empathetic = empathetic_group['Treatment Outcomes']
treatment_rational = rational_group['Treatment Outcomes']

empathy_ttest = ttest_ind(empathy_empathetic, empathy_rational, equal_var=False)
satisfaction_ttest = ttest_ind(satisfaction_empathetic, satisfaction_rational, equal_var=False)
treatment_ttest = ttest_ind(treatment_empathetic, treatment_rational, equal_var=False)

ttest_results = pd.DataFrame({
    'Measure': ['Empathy', 'User Satisfaction', 'Treatment Outcomes'],
    't-statistic': [empathy_ttest.statistic, satisfaction_ttest.statistic, treatment_ttest.statistic],
    'p-value': [empathy_ttest.pvalue, satisfaction_ttest.pvalue, treatment_ttest.pvalue]
})
print("\nH5 (Advice Style) T-test Results:\n", ttest_results)

fig, axes = plt.subplots(1, 3, figsize=(18, 6))
palette = {'empathetic': '#ADD8E6', 'rational': '#A1D99B'}
order = ['empathetic', 'rational']
for i, (y, title) in enumerate(zip(
    ['Level of empathy percieved', 'User satisfaction', 'Treatment Outcomes'],
    ['Empathy', 'User Satisfaction', 'Treatment Outcomes']
)):
    sns.boxplot(x='Participant Advice Style', y=y, data=df, ax=axes[i], order=order, palette=palette, showmeans=True,
                meanprops={"marker":"o", "markerfacecolor":"white", "markeredgecolor":"black"})
    axes[i].set_title(title)
    axes[i].set_xlabel("")
    axes[i].set_ylabel(y)
fig.suptitle("Effect of Style of Advice on Empathy, Satisfaction and Treatment Outcomes", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('Extra1.png', dpi=300)
plt.show()

# --- H6: Topic of Discussion Impact on Outcome Variables ---
topic_analysis_df = df[['Participant Problem', 'Level of empathy percieved', 'User satisfaction', 'Treatment Outcomes']].rename(
    columns={
        'Level of empathy percieved': 'Empathy',
        'User satisfaction': 'User_Satisfaction',
        'Treatment Outcomes': 'Treatment_Outcomes',
        'Participant Problem': 'Topic'
    }
)
def analyze_topic_anova(outcome):
    model = ols(f'{outcome} ~ C(Topic)', data=topic_analysis_df).fit()
    anova_results = sm.stats.anova_lm(model, typ=2)
    f_value = anova_results.loc['C(Topic)', 'F']
    p_value = anova_results.loc['C(Topic)', 'PR(>F)']
    print(f"{outcome}: F = {f_value:.2f}, p = {p_value:.3f}")
    return f_value, p_value

print("\nH6: ANOVA - Topic of Discussion")
for outcome in ['Empathy', 'User_Satisfaction', 'Treatment_Outcomes']:
    analyze_topic_anova(outcome)

# --- Tukey HSD: Pairwise Comparison of Topics ---
def run_tukey_df(outcome_column, group_column='Participant Problem'):
    tukey_result = pairwise_tukeyhsd(
        endog=df[outcome_column],
        groups=df[group_column],
        alpha=0.05
    )
    tukey_df = pd.DataFrame(data=tukey_result._results_table.data[1:], columns=tukey_result._results_table.data[0])
    return tukey_df

print("\nTukey HSD - Empathy")
print(run_tukey_df('Level of empathy percieved'))
print("\nTukey HSD - Satisfaction")
print(run_tukey_df('User satisfaction'))
print("\nTukey HSD - Treatment Outcomes")
print(run_tukey_df('Treatment Outcomes'))

# Just check H5 again
import pandas as pd
import statsmodels.api as sm
from statsmodels.formula.api import ols

# DataFrame
df['AI Transparency'] = df['Participant Told Chat With'].replace({'human': 'AI-Unaware', 'AI': 'AI-Aware'})

# Create binary variable for Acceptance Level (High / Low based on median)
median_acceptance = df["Technology acceptance rate"].median()
df["Acceptance_Level"] = df["Technology acceptance rate"].apply(lambda x: "High" if x >= median_acceptance else "Low")

# Two-way ANOVA for Empathy
model_empathy = ols("Q('Level of empathy percieved') ~ C(Acceptance_Level) * C(Q('AI Transparency'))", data=df).fit()
anova_empathy = sm.stats.anova_lm(model_empathy, typ=2)

# Two-way ANOVA for Satisfaction
model_satisfaction = ols("Q('User satisfaction') ~ C(Acceptance_Level) * C(Q('AI Transparency'))", data=df).fit()
anova_satisfaction = sm.stats.anova_lm(model_satisfaction, typ=2)

# Two-way ANOVA for Treatment Outcomes
model_outcomes = ols("Q('Treatment Outcomes') ~ C(Acceptance_Level) * C(Q('AI Transparency'))", data=df).fit()
anova_outcomes = sm.stats.anova_lm(model_outcomes, typ=2)

print("\n--- ANOVA for Empathy ---\n", anova_empathy)
print("\n--- ANOVA for Satisfaction ---\n", anova_satisfaction)
print("\n--- ANOVA for Treatment Outcomes ---\n", anova_outcomes)

"""### Qualitative Part"""

!pip install PyPDF2

# Step 1: Extract and Clean All [User] and [bot] Messages from PDF

import PyPDF2
import re


pdf_path = '/content/merged_conversations_reportlab.pdf'

user_msgs = []
bot_msgs = []

with open(pdf_path, 'rb') as f:
    reader = PyPDF2.PdfReader(f)
    text = ""
    for page in reader.pages:
        text += page.extract_text() + "\n"

# Pattern to match [User] and [Bot] messages
pattern = r'\[(User|Bot)\][^\n]*\n(.*?)(?=\[User\]|\[Bot\]|\Z)'

for match in re.finditer(pattern, text, re.DOTALL):
    role, msg = match.groups()
    msg = re.sub(r'\s+', ' ', msg).strip()
    if role == 'User':
        user_msgs.append(msg)
    else:
        bot_msgs.append(msg)

print("Sample user messages:", user_msgs[:3])
print("Sample bot messages:", bot_msgs[:3])
print("Total user messages:", len(user_msgs))
print("Total bot messages:", len(bot_msgs))

!pip install nltk gensim pyLDAvis wordcloud

# Step 2: Topic Modeling on User Messages

import nltk
from nltk.corpus import stopwords
from gensim import corpora, models
import pyLDAvis.gensim_models
from wordcloud import WordCloud
import matplotlib.pyplot as plt

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Preprocess user messages
def preprocess(texts):
    return [
        [word for word in re.sub(r'[^a-zA-Z ]', '', msg).lower().split() if word not in stop_words and len(word) > 2]
        for msg in texts
    ]

user_tokens = preprocess(user_msgs)

# Create dictionary and corpus
dictionary = corpora.Dictionary(user_tokens)
corpus = [dictionary.doc2bow(text) for text in user_tokens]

# LDA model
lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15, random_state=42)

# Print topics --> start from 0
for idx, topic in lda_model.print_topics(-1):
    print(f"Topic {idx}: {topic}")

# Visualize topics with pyLDAvis
pyLDAvis.enable_notebook()
vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)
pyLDAvis.display(vis)

# Word cloud for each topic
for t in range(5):
    plt.figure()
    plt.imshow(WordCloud(background_color='white').fit_words(dict(lda_model.show_topic(t, 30))))
    plt.axis('off')
    plt.title(f'Topic {t}')
    plt.show()

# Step 2.1 topic modeling for bot messages

# Preprocess bot messages
bot_tokens = preprocess(bot_msgs)  # Reuse the preprocess function from before

# Create dictionary and corpus for bot messages
bot_dictionary = corpora.Dictionary(bot_tokens)
bot_corpus = [bot_dictionary.doc2bow(text) for text in bot_tokens]

# LDA model for bot messages
bot_lda_model = models.LdaModel(bot_corpus, num_topics=5, id2word=bot_dictionary, passes=15, random_state=42)

# Print topics
for idx, topic in bot_lda_model.print_topics(-1):
    print(f"Bot Topic {idx}: {topic}")

# Word cloud for each bot topic
for t in range(5):
    plt.figure()
    plt.imshow(WordCloud(background_color='white').fit_words(dict(bot_lda_model.show_topic(t, 30))))
    plt.axis('off')
    plt.title(f'Bot Topic {t}')
    plt.show()

# Step 3: Sentiment Analysis with Plots

import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
import matplotlib.pyplot as plt
import seaborn as sns

nltk.download('vader_lexicon')

sia = SentimentIntensityAnalyzer()

# Get sentiment scores for user and bot messages
user_sentiments = [sia.polarity_scores(msg)['compound'] for msg in user_msgs]
bot_sentiments = [sia.polarity_scores(msg)['compound'] for msg in bot_msgs]

# Plot sentiment distributions
plt.figure(figsize=(10,6))
sns.histplot(user_sentiments, bins=30, color='blue', label='User', kde=True, stat='density')
sns.histplot(bot_sentiments, bins=30, color='green', label='Bot', kde=True, stat='density')
plt.title('Sentiment Distribution: User vs Bot')
plt.xlabel('Compound Sentiment Score')
plt.ylabel('Density')
plt.legend()
plt.tight_layout()
plt.show()

# Boxplot for comparison
plt.figure(figsize=(8,5))
sns.boxplot(data=[user_sentiments, bot_sentiments], palette=['blue', 'green'])
plt.xticks([0,1], ['User', 'Bot'])
plt.title('Sentiment Score Comparison')
plt.ylabel('Compound Sentiment Score')
plt.tight_layout()
plt.show()

# Print summary statistics
import numpy as np
print("User Sentiment: Mean =", np.mean(user_sentiments), "Std =", np.std(user_sentiments))
print("Bot Sentiment: Mean =", np.mean(bot_sentiments), "Std =", np.std(bot_sentiments))

# Step 5: Advanced Text Mining & Visualization

# 5.1 TF-IDF Keyword Extraction
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

def get_top_tfidf_words(texts, n=15):
    vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)
    X = vectorizer.fit_transform([' '.join(tokens) for tokens in texts])
    indices = X.mean(axis=0).argsort()[0, -n:][::-1].tolist()[0]
    features = vectorizer.get_feature_names_out()
    return [features[i] for i in indices]

user_top_words = get_top_tfidf_words(user_tokens)
bot_top_words = get_top_tfidf_words(bot_tokens)

print("Top User Keywords:", user_top_words)
print("Top Bot Keywords:", bot_top_words)

# 5.2 Bigram/Trigram Frequency Plots

from collections import Counter
import itertools

def plot_ngrams(tokens_list, n=2, title=''):
    ngrams = list(itertools.chain.from_iterable(
        zip(*[tokens[i:] for i in range(n)]) for tokens in tokens_list if len(tokens) >= n
    ))
    ngram_counts = Counter([' '.join(ng) for ng in ngrams])
    common = ngram_counts.most_common(10)
    df = pd.DataFrame(common, columns=['ngram', 'count'])
    plt.figure(figsize=(8,4))
    sns.barplot(data=df, x='count', y='ngram', palette='mako')
    plt.title(f'Top {n}-grams: {title}')
    plt.xlabel('Count')
    plt.ylabel(f'{n}-gram')
    plt.tight_layout()
    plt.show()

plot_ngrams(user_tokens, n=2, title='User')
plot_ngrams(bot_tokens, n=2, title='Bot')
plot_ngrams(user_tokens, n=3, title='User')
plot_ngrams(bot_tokens, n=3, title='Bot')

# 5.3. Co-occurrence Network Graph

import networkx as nx

def plot_cooccurrence(tokens_list, top_n=20, title=''):
    cooc = Counter()
    for tokens in tokens_list:
        for pair in itertools.combinations(set(tokens), 2):
            cooc[tuple(sorted(pair))] += 1
    common = cooc.most_common(top_n)
    G = nx.Graph()
    for (w1, w2), count in common:
        G.add_edge(w1, w2, weight=count)
    plt.figure(figsize=(8,8))
    pos = nx.spring_layout(G, k=0.5)
    nx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', width=[d['weight']/2 for (u,v,d) in G.edges(data=True)], font_size=10)
    plt.title(f'Co-occurrence Network: {title}')
    plt.show()

plot_cooccurrence(user_tokens, title='User')
plot_cooccurrence(bot_tokens, title='Bot')

# 5.4. t-SNE Clustering Plot

from sklearn.manifold import TSNE
from sklearn.feature_extraction.text import TfidfVectorizer

def tsne_plot(tokens_list, title=''):
    texts = [' '.join(tokens) for tokens in tokens_list]
    vectorizer = TfidfVectorizer(max_features=100)
    X = vectorizer.fit_transform(texts).toarray()
    tsne = TSNE(n_components=2, random_state=42, perplexity=30)
    X_embedded = tsne.fit_transform(X)
    plt.figure(figsize=(7,7))
    plt.scatter(X_embedded[:,0], X_embedded[:,1], alpha=0.6, s=30, c='navy')
    plt.title(f't-SNE Clustering: {title}')
    plt.xlabel('t-SNE 1')
    plt.ylabel('t-SNE 2')
    plt.tight_layout()
    plt.show()

tsne_plot(user_tokens, title='User')
tsne_plot(bot_tokens, title='Bot')

# Flowchart

from graphviz import Digraph

dot = Digraph(comment='Overview of Study Design and Experimental Flow', format='png')
dot.attr(rankdir='TB', fontsize='20', fontname='Arial')

# Main steps
dot.node('A', 'Participant Recruitment\n(Prolific)', shape='box', style='rounded,filled', fillcolor='#e3f2fd')
dot.node('B', 'Pre-Interaction Survey\n(AI Acceptance via TAM, Type of Care preferences)', shape='box', style='rounded,filled', fillcolor='#e3f2fd')
dot.node('C', 'Randomization:\nAI Transparency Condition', shape='box', style='rounded,filled', fillcolor='#e3f2fd')

# Branches for AI Transparency
dot.node('D1', 'Told "AI Therapist"\n(AI-Aware)', shape='box', style='rounded,filled', fillcolor='#fff3e0')
dot.node('D2', 'Told "Human Therapist"\n(AI-Unaware)', shape='box', style='rounded,filled', fillcolor='#fff3e0')

# Advice style
dot.node('E1', 'Empathetic Advice', shape='box', style='rounded,filled', fillcolor='#e8f5e9')
dot.node('E2', 'Rational Advice', shape='box', style='rounded,filled', fillcolor='#e8f5e9')
dot.node('E3', 'Empathetic Advice', shape='box', style='rounded,filled', fillcolor='#e8f5e9')
dot.node('E4', 'Rational Advice', shape='box', style='rounded,filled', fillcolor='#e8f5e9')

# Experimental groups
dot.node('F1', '(1) AI-Aware, Empathetic', shape='box', style='rounded,filled', fillcolor='#f3e5f5')
dot.node('F2', '(2) AI-Aware, Rational', shape='box', style='rounded,filled', fillcolor='#f3e5f5')
dot.node('F3', '(3) AI-Unaware, Empathetic', shape='box', style='rounded,filled', fillcolor='#f3e5f5')
dot.node('F4', '(4) AI-Unaware, Rational', shape='box', style='rounded,filled', fillcolor='#f3e5f5')

# Merge to chatbot session
dot.node('G', 'Chatbot Session (Flowise Implementation)\nTopic selection: Anxiety, Depression, or Stress\n10-minute text-based conversation\nChat logs recorded', shape='box', style='rounded,filled', fillcolor='#e1f5fe')

dot.node('H', 'Post-Interaction Survey\n(Perceived Empathy via JSPE, Treatment Outcomes via SIS, User Satisfaction via PSQ-III)', shape='box', style='rounded,filled', fillcolor='#ffe0b2')
dot.node('I', 'Data Analysis\nQuantitative: Hypothesis testing, ANOVA, t-tests\nQualitative: Topic modeling, sentiment analysis, clustering', shape='box', style='rounded,filled', fillcolor='#c8e6c9')

# Edges
dot.edge('A', 'B')
dot.edge('B', 'C')
dot.edge('C', 'D1')
dot.edge('C', 'D2')
dot.edge('D1', 'E1')
dot.edge('D1', 'E2')
dot.edge('D2', 'E3')
dot.edge('D2', 'E4')
dot.edge('E1', 'F1')
dot.edge('E2', 'F2')
dot.edge('E3', 'F3')
dot.edge('E4', 'F4')
dot.edges([('F1', 'G'), ('F2', 'G'), ('F3', 'G'), ('F4', 'G')])
dot.edge('G', 'H')
dot.edge('H', 'I')

# Render the diagram
dot.render('study_design_flowchart', view=False)
print("Flowchart updated successfully!")

# Display the source code for verification
print("\nUpdated flowchart source:")
print(dot.source)